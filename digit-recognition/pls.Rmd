---
title: "Exercise - PLS2. ZIP data"
output: html_document
---

```{r, message=FALSE}
library(pls)
```

**1**

**Read the "zip_train.dat" and "zip_test.dat" files provided.**

```{r}
train <- read.table('data/zip_train.dat')
test <- read.table('data/zip_test.dat')
```

**Select the same 5% random sample (without replacement) of the train data used in exercise 1.**

Our training dataset consists of 7291 samples. By choosing 5\% of data we shrink it down to 364. By doing so we will try to fit the model with number of observations close to the number	 of the parameters (in this case 256). Such a datasets are the target of PCR method.

```{r}
train.samples <- sample(nrow(train), 0.05 * nrow(train))
n <- length(train.samples)
```

**Use this sample as your training data, and the complete test data for testing.**

```{r}
X.train <- as.matrix(train[train.samples, -1])
Y.train <- train[train.samples, 1]

X.test <- as.matrix(test[, -1])
Y.test <- test[, 1]
```

**2**

**Define the response matrix (Y) and the predictor matrix (X).**

X matrix was ready before.

Because the digits have to be treated as categorical variables they will be represented by one-hot encoding.

```{r}
oneHot <- function(x) {
  result <- rep(0, 10)
  result[x + 1] <- 1
  return(result)
}

Y.train.one.hot <- t(sapply(Y.train, oneHot))
Y.test.one.hot <- t(sapply(Y.test, oneHot))
```

**Center the predictor matrix.**

```{r}
X.train <- scale(X.train, scale = FALSE)
X.test <- scale(X.test, scale = FALSE)
```

**3**

**Perform a PLSR2 using “CV” or “LOO” for validation.**

```{r}
ncomp <- 50
pls <- plsr(Y.train.one.hot ~ X.train, ncomp = ncomp, validation = "LOO")
```

**Decide how many components you retain for prediction?**

In order to assess the models the bias-corrected cross-validation estimate will be plotted as the function of the number of components.

For each response the `adjCV` score will be weighted by the number of it's representatives in the training sample.

```{r}
adjCV <- RMSEP(pls)$val[2,,]
adjCV.weighted <- as.numeric(colSums(Y.train.one.hot) %*% adjCV / sum(colSums(Y.train.one.hot)))
plot(0:ncomp, adjCV.weighted)
```

The number of components that optimize the value of `adjCV` is (1 is subtracted, because the first model has no components, only the intercept):

```{r}
which.min(adjCV.weighted) - 1
```

Nevertheless other numbers of components will be tested to see the error rate on the test data.

In order to calculate the R2 score the following function is defined:

```{r}
getR2 <- function(Y.one.hot, pred.one.hot) {
  TSS = diag(t(Y.one.hot) %*% Y.test.one.hot)
  RSS = diag(t(Y.one.hot - pred.one.hot) %*% (Y.one.hot - pred.one.hot))
  return(1 - (RSS / TSS))
}
```

The `pred` function defined below will be applied over the vector of components numbers:

```{r}
pred <- function(pls, Y.train.one.hot, X.test, Y.test.one.hot, comps) {
  m <- lm(Y.train.one.hot ~ pls$scores[, 1:comps])
  projection <- X.test %*% pls$projection[, 1:comps]
  pred.one.hot <- projection %*% m$coefficients[-1, ] + m$coefficients[1, ]  
  r2 <- getR2(Y.test.one.hot, pred.one.hot)
  mean.r2 <- sum(colSums(Y.train.one.hot) * r2) / sum(colSums(Y.train.one.hot))
  pred <- apply(pred.one.hot, 1, which.max) - 1
  error <- sum(Y.test != pred) / length(pred)
  return(c(comps = comps,
           mean.r2 = mean.r2,
           error = error))
}
```

```{r}
preds <- t(sapply(1:ncomp, function(comps) pred(pls, Y.train.one.hot, X.test, Y.test.one.hot, comps)))
preds <- as.data.frame(preds)
```

**Compute the average R2 in the test data.**

The average R2 as the function of the number of components:

```{r}
plot(preds$comps, preds$mean.r2)
```

The number of components that maximizes the average coefficient of determination of the test data is: 

```{r}
preds$c[which.max(preds$mean.r2)]
```

**5**

**Assign every test individual to the maximum response and compute the error rate.**

```{r}
plot(preds$c, preds$error)
```

The number of components that minimizes the error rate on the test data is: 

```{r}
preds$c[which.min(preds$error)]
```

And finally, the error rate obtained with them is equal to:

```{r}
min(preds$error)
```

It might be also interesting to check what is the error rate obtained with the number of components that has maximized the $R^2$ score:

```{r}
preds$error[which.max(preds$mean.r2)]
```